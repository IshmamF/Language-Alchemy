{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IshmamF/youtube-translation/blob/main/PrimeHackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Youtube Videos Transcription with OpenAI's Whisper**\n",
        "\n",
        "[![blog post shield](https://img.shields.io/static/v1?label=&message=Blog%20post&color=blue&style=for-the-badge&logo=openai&link=https://openai.com/blog/whisper)](https://openai.com/blog/whisper)\n",
        "[![notebook shield](https://img.shields.io/static/v1?label=&message=Notebook&color=blue&style=for-the-badge&logo=googlecolab&link=https://colab.research.google.com/github/ArthurFDLR/whisper-youtube/blob/main/whisper_youtube.ipynb)](https://colab.research.google.com/github/ArthurFDLR/whisper-youtube/blob/main/whisper_youtube.ipynb)\n",
        "[![repository shield](https://img.shields.io/static/v1?label=&message=Repository&color=blue&style=for-the-badge&logo=github&link=https://github.com/openai/whisper)](https://github.com/openai/whisper)\n",
        "[![paper shield](https://img.shields.io/static/v1?label=&message=Paper&color=blue&style=for-the-badge&link=https://cdn.openai.com/papers/whisper.pdf)](https://cdn.openai.com/papers/whisper.pdf)\n",
        "[![model card shield](https://img.shields.io/static/v1?label=&message=Model%20card&color=blue&style=for-the-badge&link=https://github.com/openai/whisper/blob/main/model-card.md)](https://github.com/openai/whisper/blob/main/model-card.md)\n",
        "\n",
        "Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.\n",
        "\n",
        "This Notebook will guide you through the transcription of a Youtube video using Whisper. You'll be able to explore most inference parameters or use the Notebook as-is to store the transcript and video audio in your Google Drive."
      ],
      "metadata": {
        "id": "96kvih9mXkNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Check GPU type** üïµÔ∏è\n",
        "\n",
        "#@markdown The type of GPU you get assigned in your Colab session defined the speed at which the video will be transcribed.\n",
        "#@markdown The higher the number of floating point operations per second (FLOPS), the faster the transcription.\n",
        "#@markdown But even the least powerful GPU available in Colab is able to run any Whisper model.\n",
        "#@markdown Make sure you've selected `GPU` as hardware accelerator for the Notebook (Runtime &rarr; Change runtime type &rarr; Hardware accelerator).\n",
        "\n",
        "#@markdown |  GPU   |  GPU RAM   | FP32 teraFLOPS |     Availability   |\n",
        "#@markdown |:------:|:----------:|:--------------:|:------------------:|\n",
        "#@markdown |  T4    |    16 GB   |       8.1      |         Free       |\n",
        "#@markdown | P100   |    16 GB   |      10.6      |      Colab Pro     |\n",
        "#@markdown | V100   |    16 GB   |      15.7      |  Colab Pro (Rare)  |\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Factory reset your Notebook's runtime if you want to get assigned a new GPU.**\n",
        "\n",
        "!nvidia-smi -L\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "QshUbLqpX7L4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7167fb17-d457-461b-bfbc-7fb07b4a9041"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-a20f027e-9be4-86e4-97be-96d51bf1e165)\n",
            "Sun Nov 19 11:47:07 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IfG0E_WbRFI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50f2aa1e-9eec-4a8a-90f2-45875598f447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-5spi3qno\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-5spi3qno\n",
            "  Resolved https://github.com/openai/whisper.git to commit e58f28804528831904c3b6f2c0e473f346223433\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801358 sha256=ba7c7c3bb2e759a759042b2d6a64addf0d746d4b9b19e49e193ad0f049c0a360\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e6o9rqc8/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20231117 tiktoken-0.5.1\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2023.11.16-py2.py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mutagen (from yt-dlp)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt-dlp)\n",
            "  Downloading pycryptodomex-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets (from yt-dlp)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2023.7.22)\n",
            "Requirement already satisfied: requests<3,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.0.7)\n",
            "Collecting brotli (from yt-dlp)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt-dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt-dlp) (3.4)\n",
            "Installing collected packages: brotli, websockets, pycryptodomex, mutagen, yt-dlp\n",
            "Successfully installed brotli-1.1.0 mutagen-1.47.0 pycryptodomex-3.19.0 websockets-12.0 yt-dlp-2023.11.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **Install libraries** üèóÔ∏è\n",
        "#@markdown This cell will take a little while to download several libraries, including Whisper.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install yt-dlp\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "import whisper\n",
        "from pathlib import Path\n",
        "import yt_dlp\n",
        "import subprocess\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "from IPython.display import display, Markdown, YouTubeVideo\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zwGAsr4sIgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62739c59-c96b-4d58-9e65-c08b8cbc0079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **Optional:** Save data in Google Drive üíæ\n",
        "#@markdown Enter a Google Drive path and run this cell if you want to store the results inside Google Drive.\n",
        "\n",
        "# Uncomment to copy generated images to drive, faster than downloading directly from colab in my experience.\n",
        "from google.colab import drive\n",
        "drive_mount_path = Path(\"/\") / \"content\" / \"drive\"\n",
        "drive.mount(str(drive_mount_path))\n",
        "drive_mount_path /= \"My Drive\"\n",
        "#@markdown ---\n",
        "drive_path = \"Colab Notebooks/Whisper Youtube\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change your Google Drive path.**\n",
        "\n",
        "drive_whisper_path = drive_mount_path / Path(drive_path.lstrip(\"/\"))\n",
        "drive_whisper_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Model selection** üß†\n",
        "\n",
        "#@markdown As of the first public release, there are 4 pre-trained options to play with:\n",
        "\n",
        "#@markdown |  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "#@markdown |:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
        "#@markdown |  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
        "#@markdown |  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
        "#@markdown | small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
        "#@markdown | medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
        "#@markdown | large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |\n",
        "\n",
        "#@markdown ---\n",
        "Model = 'large' #@param ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large']\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the model.**\n",
        "\n",
        "whisper_model = whisper.load_model(Model)\n",
        "\n",
        "if Model in whisper.available_models():\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is selected.**\"\n",
        "    ))\n",
        "else:\n",
        "    display(Markdown(\n",
        "        f\"**{Model} model is no longer available.**<br /> Please select one of the following:<br /> - {'<br /> - '.join(whisper.available_models())}\"\n",
        "    ))"
      ],
      "metadata": {
        "id": "TMhrSq_GZ6kA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "a7bb6a18-6cdb-4418-fc4f-22756de6785b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 815M/2.88G [00:04<00:12, 184MiB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b612ae7ccc4e>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#@markdown **Run this cell again if you change the model.**\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mwhisper_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mModel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwhisper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavailable_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/__init__.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, device, download_root, in_memory)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_MODELS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mcheckpoint_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MODELS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0malignment_heads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ALIGNMENT_HEADS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/__init__.py\u001b[0m in \u001b[0;36m_download\u001b[0;34m(url, root, in_memory)\u001b[0m\n\u001b[1;32m     76\u001b[0m         ) as loop:\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8192\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    464\u001b[0m                 \u001b[0;31m# clip the read to the \"end of response\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0mamt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1272\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribeVideo():\n",
        "\n",
        "  if Type == \"Youtube video or playlist\":\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'm4a/bestaudio/best',\n",
        "        'outtmpl': '%(id)s.%(ext)s',\n",
        "        # ‚ÑπÔ∏è See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments\n",
        "        'postprocessors': [{  # Extract audio using ffmpeg\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        error_code = ydl.download([URL])\n",
        "        list_video_info = [ydl.extract_info(URL, download=False)]\n",
        "\n",
        "    for video_info in list_video_info:\n",
        "        video_path_local_list.append(Path(f\"{video_info['id']}.wav\"))\n",
        "\n",
        "  elif Type == \"Google Drive\":\n",
        "    # video_path_drive = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    video_path = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    if video_path.is_dir():\n",
        "      for video_path_drive in video_path.glob(\"**/*\"):\n",
        "        if video_path_drive.is_file():\n",
        "          display(Markdown(f\"**{str(video_path_drive)} selected for transcription.**\"))\n",
        "        elif video_path_drive.is_dir():\n",
        "          display(Markdown(f\"**Subfolders not supported.**\"))\n",
        "        else:\n",
        "          display(Markdown(f\"**{str(video_path_drive)} does not exist, skipping.**\"))\n",
        "        video_path_local = Path(\".\").resolve() / (video_path_drive.name)\n",
        "        shutil.copy(video_path_drive, video_path_local)\n",
        "        video_path_local_list.append(video_path_local)\n",
        "    elif video_path.is_file():\n",
        "      video_path_local = Path(\".\").resolve() / (video_path.name)\n",
        "      shutil.copy(video_path, video_path_local)\n",
        "      video_path_local_list.append(video_path_local)\n",
        "      display(Markdown(f\"**{str(video_path)} selected for transcription.**\"))\n",
        "    else:\n",
        "      display(Markdown(f\"**{str(video_path)} does not exist.**\"))\n",
        "\n",
        "  else:\n",
        "    raise(TypeError(\"Please select supported input type.\"))\n",
        "\n",
        "  for video_path_local in video_path_local_list:\n",
        "    if video_path_local.suffix == \".mp4\":\n",
        "      video_path_local = video_path_local.with_suffix(\".wav\")\n",
        "      result  = subprocess.run([\"ffmpeg\", \"-i\", str(video_path_local.with_suffix(\".mp4\")), \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", str(video_path_local)])\n"
      ],
      "metadata": {
        "id": "YVaLUSOgSteI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translateLang():\n",
        "\n",
        "  language = \"English\"\n",
        "  verbose = 'Live transcription'\n",
        "  output_format = 'all'\n",
        "  task = 'translate'\n",
        "  temperature = 0.15\n",
        "  temperature_increment_on_fallback = 0.2\n",
        "  best_of = 5\n",
        "  beam_size = 8\n",
        "  patience = 1.0\n",
        "  length_penalty = -0.05\n",
        "  suppress_tokens = \"-1\"\n",
        "  initial_prompt = \"\"\n",
        "  condition_on_previous_text = True\n",
        "  fp16 = True\n",
        "  compression_ratio_threshold = 2.4\n",
        "  logprob_threshold = -1.0\n",
        "  no_speech_threshold = 0.6\n",
        "\n",
        "  verbose_lut = {\n",
        "      'Live transcription': True,\n",
        "      'Progress bar': False,\n",
        "      'None': None\n",
        "  }\n",
        "\n",
        "  args = dict(\n",
        "      language = (None if language == \"Auto detection\" else language),\n",
        "      verbose = verbose_lut[verbose],\n",
        "      task = task,\n",
        "      temperature = temperature,\n",
        "      temperature_increment_on_fallback = temperature_increment_on_fallback,\n",
        "      best_of = best_of,\n",
        "      beam_size = beam_size,\n",
        "      patience=patience,\n",
        "      length_penalty=(length_penalty if length_penalty>=0.0 else None),\n",
        "      suppress_tokens=suppress_tokens,\n",
        "      initial_prompt=(None if not initial_prompt else initial_prompt),\n",
        "      condition_on_previous_text=condition_on_previous_text,\n",
        "      fp16=fp16,\n",
        "      compression_ratio_threshold=compression_ratio_threshold,\n",
        "      logprob_threshold=logprob_threshold,\n",
        "      no_speech_threshold=no_speech_threshold\n",
        "  )\n",
        "\n",
        "  temperature = args.pop(\"temperature\")\n",
        "  temperature_increment_on_fallback = args.pop(\"temperature_increment_on_fallback\")\n",
        "  if temperature_increment_on_fallback is not None:\n",
        "      temperature = tuple(np.arange(temperature, 1.0 + 1e-6, temperature_increment_on_fallback))\n",
        "  else:\n",
        "      temperature = [temperature]\n",
        "\n",
        "  if Model.endswith(\".en\") and args[\"language\"] not in {\"en\", \"English\"}:\n",
        "      warnings.warn(f\"{Model} is an English-only model but receipted '{args['language']}'; using English instead.\")\n",
        "      args[\"language\"] = \"en\"\n",
        "\n",
        "  for video_path_local in video_path_local_list:\n",
        "      display(Markdown(f\"### {video_path_local}\"))\n",
        "\n",
        "      video_transcription = whisper.transcribe(\n",
        "          whisper_model,\n",
        "          str(video_path_local),\n",
        "          temperature=temperature,\n",
        "          **args,\n",
        "      )\n",
        "\n",
        "      # Save output\n",
        "      whisper.utils.get_writer(\n",
        "          output_format=output_format,\n",
        "          output_dir=video_path_local.parent\n",
        "      )(\n",
        "          video_transcription,\n",
        "          str(video_path_local.stem),\n",
        "          options=dict(\n",
        "              highlight_words=False,\n",
        "              max_line_count=None,\n",
        "              max_line_width=None,\n",
        "          )\n",
        "      )\n",
        "\n",
        "      def exportTranscriptFile(ext: str):\n",
        "          local_path = video_path_local.parent / video_path_local.with_suffix(ext)\n",
        "          export_path = drive_whisper_path / video_path_local.with_suffix(ext)\n",
        "          shutil.copy(\n",
        "              local_path,\n",
        "              export_path\n",
        "          )\n",
        "          display(Markdown(f\"**Transcript file created: {export_path}**\"))\n",
        "\n",
        "      if output_format==\"all\":\n",
        "          for ext in ('.txt', '.vtt', '.srt', '.tsv', '.json'):\n",
        "              exportTranscriptFile(ext)\n",
        "      else:\n",
        "          exportTranscriptFile(\".\" + output_format)\n"
      ],
      "metadata": {
        "id": "lGNRhmz4VCsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok==4.1.1"
      ],
      "metadata": {
        "id": "FD8eKL9lVmVh",
        "outputId": "a6a0c495-20e2-4634-981d-f6b76b43c7ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.28.2-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.8.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.2)\n",
            "Collecting validators<1,>=0.2 (from streamlit)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.11.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.31.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Installing collected packages: watchdog, validators, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.40 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.28.2 validators-0.22.0 watchdog-3.0.0\n",
            "Collecting pyngrok==4.1.1\n",
            "  Downloading pyngrok-4.1.1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyngrok==4.1.1) (0.18.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok==4.1.1) (6.0.1)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-4.1.1-py3-none-any.whl size=15964 sha256=171c167573fc00468446b6ac7c1f7208e5297b9172389668451bd9fc0a559960\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/7c/4c/632fba2ea8e88d8890102eb07bc922e1ca8fa14db5902c91a8\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-4.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube_transcript_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLKd_Kcoe4ZT",
        "outputId": "bdcbc0ce-543b-4cb1-da8d-ee7fc81b374b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube_transcript_api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2023.7.22)\n",
            "Installing collected packages: youtube_transcript_api\n",
            "Successfully installed youtube_transcript_api-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLFhaPNggnNX",
        "outputId": "fcf9f15d-8519-4b14-e116-75d57b9114b6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import sys\n",
        "import warnings\n",
        "import whisper\n",
        "from pathlib import Path\n",
        "import yt_dlp\n",
        "import subprocess\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "import time\n",
        "import tempfile\n",
        "from IPython.display import display, Markdown, YouTubeVideo\n",
        "from transformers import pipeline\n",
        "\n",
        "def Summarizer_function(transcription):\n",
        "    summarizer = pipeline(\"summarization\")\n",
        "    def word_length(paragraph):\n",
        "      words = paragraph.split()\n",
        "      return len(words)\n",
        "    min_length = word_length(transcription)\n",
        "    if min_length >= 1800:\n",
        "    # Assuming 'summarizer' is a function you have defined elsewhere\n",
        "      summary = summarizer(transcription, max_length = 5000, min_length=150, do_sample=False)\n",
        "    elif min_length < 1800:\n",
        "    # Assuming 'summarizer' is a function you have defined elsewhere\n",
        "      summary = summarizer(transcription, max_length = 2500, min_length=50, do_sample=False)\n",
        "      return summary\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "Model = 'tiny' # ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large']\n",
        "\n",
        "whisper_model = whisper.load_model(Model)\n",
        "\n",
        "st.title(\"Language Alchemy\")\n",
        "\n",
        "st.header('Translate any youtube video in the language of your choice!')\n",
        "\n",
        "def main():\n",
        "  youtube_link = st.text_input(\"Enter YouTube Video Link\")\n",
        "  choice = st.selectbox('Select', ['Auto detection', 'Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bashkir', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Castilian', 'Catalan', 'Chinese', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Faroese', 'Finnish', 'Flemish', 'French', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hungarian', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Lao', 'Latin', 'Latvian', 'Letzeburgesch', 'Lingala', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Moldavian', 'Moldovan', 'Mongolian', 'Myanmar', 'Nepali', 'Norwegian', 'Nynorsk', 'Occitan', 'Panjabi', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Pushto', 'Romanian', 'Russian', 'Sanskrit', 'Serbian', 'Shona', 'Sindhi', 'Sinhala', 'Sinhalese', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tibetan', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'Uzbek', 'Valencian', 'Vietnamese', 'Welsh', 'Yiddish', 'Yoruba'])\n",
        "  button = st.button('Submit')\n",
        "\n",
        "  if button and youtube_link and choice:\n",
        "\n",
        "    Type = \"Youtube video or playlist\"\n",
        "    URL = youtube_link\n",
        "    video_path = \"Colab Notebooks/transcription/my_video.mp4\"\n",
        "\n",
        "    video_path_local_list = []\n",
        "\n",
        "    if Type == \"Youtube video or playlist\":\n",
        "\n",
        "      ydl_opts = {\n",
        "          'format': 'm4a/bestaudio/best',\n",
        "          'outtmpl': '%(id)s.%(ext)s',\n",
        "          # ‚ÑπÔ∏è See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments\n",
        "          'postprocessors': [{  # Extract audio using ffmpeg\n",
        "              'key': 'FFmpegExtractAudio',\n",
        "              'preferredcodec': 'wav',\n",
        "          }]\n",
        "      }\n",
        "\n",
        "      with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "          error_code = ydl.download([URL])\n",
        "          list_video_info = [ydl.extract_info(URL, download=False)]\n",
        "\n",
        "      for video_info in list_video_info:\n",
        "          video_path_local_list.append(Path(f\"{video_info['id']}.wav\"))\n",
        "\n",
        "    elif Type == \"Google Drive\":\n",
        "      # video_path_drive = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "      video_path = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "      if video_path.is_dir():\n",
        "        for video_path_drive in video_path.glob(\"**/*\"):\n",
        "          if video_path_drive.is_file():\n",
        "            display(Markdown(f\"**{str(video_path_drive)} selected for transcription.**\"))\n",
        "          elif video_path_drive.is_dir():\n",
        "            display(Markdown(f\"**Subfolders not supported.**\"))\n",
        "          else:\n",
        "            display(Markdown(f\"**{str(video_path_drive)} does not exist, skipping.**\"))\n",
        "          video_path_local = Path(\".\").resolve() / (video_path_drive.name)\n",
        "          shutil.copy(video_path_drive, video_path_local)\n",
        "          video_path_local_list.append(video_path_local)\n",
        "      elif video_path.is_file():\n",
        "        video_path_local = Path(\".\").resolve() / (video_path.name)\n",
        "        shutil.copy(video_path, video_path_local)\n",
        "        video_path_local_list.append(video_path_local)\n",
        "        display(Markdown(f\"**{str(video_path)} selected for transcription.**\"))\n",
        "      else:\n",
        "        display(Markdown(f\"**{str(video_path)} does not exist.**\"))\n",
        "\n",
        "    else:\n",
        "      raise(TypeError(\"Please select supported input type.\"))\n",
        "\n",
        "    for video_path_local in video_path_local_list:\n",
        "      if video_path_local.suffix == \".mp4\":\n",
        "        video_path_local = video_path_local.with_suffix(\".wav\")\n",
        "        result  = subprocess.run([\"ffmpeg\", \"-i\", str(video_path_local.with_suffix(\".mp4\")), \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", str(video_path_local)])\n",
        "\n",
        "\n",
        "    language = \"English\"\n",
        "    verbose = 'Live transcription'\n",
        "    output_format = 'all'\n",
        "    task = 'translate'\n",
        "    temperature = 0.15\n",
        "    temperature_increment_on_fallback = 0.2\n",
        "    best_of = 5\n",
        "    beam_size = 8\n",
        "    patience = 1.0\n",
        "    length_penalty = -0.05\n",
        "    suppress_tokens = \"-1\"\n",
        "    initial_prompt = \"\"\n",
        "    condition_on_previous_text = True\n",
        "    fp16 = True\n",
        "    compression_ratio_threshold = 2.4\n",
        "    logprob_threshold = -1.0\n",
        "    no_speech_threshold = 0.6\n",
        "\n",
        "    verbose_lut = {\n",
        "        'Live transcription': True,\n",
        "        'Progress bar': False,\n",
        "        'None': None\n",
        "    }\n",
        "\n",
        "    args = dict(\n",
        "        language = (None if language == \"Auto detection\" else language),\n",
        "        verbose = verbose_lut[verbose],\n",
        "        task = task,\n",
        "        temperature = temperature,\n",
        "        temperature_increment_on_fallback = temperature_increment_on_fallback,\n",
        "        best_of = best_of,\n",
        "        beam_size = beam_size,\n",
        "        patience=patience,\n",
        "        length_penalty=(length_penalty if length_penalty>=0.0 else None),\n",
        "        suppress_tokens=suppress_tokens,\n",
        "        initial_prompt=(None if not initial_prompt else initial_prompt),\n",
        "        condition_on_previous_text=condition_on_previous_text,\n",
        "        fp16=fp16,\n",
        "        compression_ratio_threshold=compression_ratio_threshold,\n",
        "        logprob_threshold=logprob_threshold,\n",
        "        no_speech_threshold=no_speech_threshold\n",
        "    )\n",
        "\n",
        "    temperature = args.pop(\"temperature\")\n",
        "    temperature_increment_on_fallback = args.pop(\"temperature_increment_on_fallback\")\n",
        "    if temperature_increment_on_fallback is not None:\n",
        "        temperature = tuple(np.arange(temperature, 1.0 + 1e-6, temperature_increment_on_fallback))\n",
        "    else:\n",
        "        temperature = [temperature]\n",
        "\n",
        "    if Model.endswith(\".en\") and args[\"language\"] not in {\"en\", \"English\"}:\n",
        "        warnings.warn(f\"{Model} is an English-only model but receipted '{args['language']}'; using English instead.\")\n",
        "        args[\"language\"] = \"en\"\n",
        "\n",
        "    for video_path_local in video_path_local_list:\n",
        "        display(Markdown(f\"### {video_path_local}\"))\n",
        "\n",
        "        video_transcription = whisper.transcribe(\n",
        "            whisper_model,\n",
        "            str(video_path_local),\n",
        "            temperature=temperature,\n",
        "            **args,\n",
        "        )\n",
        "\n",
        "        # Save output\n",
        "        whisper.utils.get_writer(\n",
        "            output_format=output_format,\n",
        "            output_dir=video_path_local.parent\n",
        "        )(\n",
        "            video_transcription,\n",
        "            str(video_path_local.stem),\n",
        "            options=dict(\n",
        "                highlight_words=False,\n",
        "                max_line_count=None,\n",
        "                max_line_width=None,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        def exportTranscriptFile(ext: str):\n",
        "            local_path = video_path_local.parent / video_path_local.with_suffix(ext)\n",
        "            with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
        "                temp_path = temp_file.name\n",
        "                shutil.copy(local_path, temp_path)\n",
        "                shutil.move(temp_path, local_path)\n",
        "\n",
        "        exportTranscriptFile('.txt')\n",
        "\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "    col1, col2 = st.columns([1,1])\n",
        "    with col1:\n",
        "      st.video(youtube_link)\n",
        "    with col2:\n",
        "      with st.spinner(text='In progress'):\n",
        "        max_wait_time = 75  # You can adjust this value based on your needs\n",
        "        start_time = time.time()\n",
        "\n",
        "        while not Path(f\"{video_info['id']}.txt\").is_file():\n",
        "            if time.time() - start_time > max_wait_time:\n",
        "                st.warning(\"Timeout: Unable to load the file within the specified time.\")\n",
        "                break\n",
        "            time.sleep(1)\n",
        "\n",
        "        # Assuming video_info['id'] is a placeholder for your actual video ID\n",
        "        video_file_path = f\"{video_info['id']}.txt\"\n",
        "\n",
        "        if Path(video_file_path).is_file():\n",
        "            video_file = open(video_file_path, 'r')\n",
        "            text_content = video_file.read()\n",
        "            st.text_area(\"Transcription:\", text_content, height=225)  # Adjust height as needed\n",
        "\n",
        "        else:\n",
        "            st.warning(f\"File {video_file_path} not found.\")\n",
        "    st.subheader('Summary:')\n",
        "    with st.spinner(text=\"In progress...\"):\n",
        "      summary = Summarizer_function(text_content)[0][\"summary_text\"]\n",
        "      st.write(summary)\n",
        "      time.sleep(2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CFG6YjApOAnq",
        "outputId": "11814978-d6cb-446e-fa0a-0520d7f9552c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djY30i26iQtP",
        "outputId": "e3549bc1-cdc4-43f8-b0f2-7f474edc71f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l[..................] / rollbackFailedOptional: verb npm-session f3bebcef8edaadc\u001b[0m\u001b[K\r[..................] / rollbackFailedOptional: verb npm-session f3bebcef8edaadc\u001b[0m\u001b[K\r[..................] / rollbackFailedOptional: verb npm-session f3bebcef8edaadc\u001b[0m\u001b[K\r\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.124.244.140:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.199s\n",
            "your url is: https://tall-papayas-eat.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token('2YNwFxrosM2EhDHzpfZt8RP4ozL_57TYy1E5dAo47h7XKmyXX')\n"
      ],
      "metadata": {
        "id": "DILKbsZeWrrj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8991561d-d2a6-41dc-c8f5-46de17c6288c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Set up a new tunnel\n",
        "site = ngrok.connect(port=8501)\n",
        "\n",
        "# Run the Streamlit app as a background process\n",
        "!nohup streamlit run app.py &\n",
        "\n",
        "# Print the public URL to access the Streamlit app\n",
        "print('Streamlit URL:', site)"
      ],
      "metadata": {
        "id": "_ohMtLBma4c3",
        "outputId": "f48a53af-8779-4f31-b611-aa29a206f4fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "Streamlit URL: http://ac1a-35-185-180-67.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "4KN9cTDwjIRy",
        "outputId": "62276860-debf-42ac-f1f3-854dd7e1715f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-68214366f313>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPv2Tunnel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'HTTPv2Tunnel'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py --server.port 8888\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1siOr4kwjCeL",
        "outputId": "f0b2ca91-1d03-4255-9dcc-1ae0126ef1e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8888\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.124.244.140:8888\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gr-_s17SjE9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Video selection** üì∫\n",
        "\n",
        "#@markdown Enter the URL of the Youtube video you want to transcribe, wether you want to save the audio file in your Google Drive, and run the cell.\n",
        "\n",
        "Type = \"Youtube video or playlist\" #@param ['Youtube video or playlist', 'Google Drive']\n",
        "#@markdown ---\n",
        "#@markdown #### **Youtube video or playlist**\n",
        "URL = \"https://www.youtube.com/watch?v=tWCaFVJMUi8&ab_channel=GateSmashers\" #@param {type:\"string\"}\n",
        "# store_audio = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #### **Google Drive video, audio (mp4, wav), or folder containing video and/or audio files**\n",
        "video_path = \"Colab Notebooks/transcription/my_video.mp4\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the video.**\n",
        "\n",
        "video_path_local_list = []\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'm4a/bestaudio/best',\n",
        "        'outtmpl': '%(id)s.%(ext)s',\n",
        "        # ‚ÑπÔ∏è See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments\n",
        "        'postprocessors': [{  # Extract audio using ffmpeg\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        error_code = ydl.download([URL])\n",
        "        list_video_info = [ydl.extract_info(URL, download=False)]\n",
        "\n",
        "    for video_info in list_video_info:\n",
        "        video_path_local_list.append(Path(f\"{video_info['id']}.wav\"))\n",
        "\n",
        "elif Type == \"Google Drive\":\n",
        "    # video_path_drive = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    video_path = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    if video_path.is_dir():\n",
        "        for video_path_drive in video_path.glob(\"**/*\"):\n",
        "            if video_path_drive.is_file():\n",
        "                display(Markdown(f\"**{str(video_path_drive)} selected for transcription.**\"))\n",
        "            elif video_path_drive.is_dir():\n",
        "                display(Markdown(f\"**Subfolders not supported.**\"))\n",
        "            else:\n",
        "                display(Markdown(f\"**{str(video_path_drive)} does not exist, skipping.**\"))\n",
        "            video_path_local = Path(\".\").resolve() / (video_path_drive.name)\n",
        "            shutil.copy(video_path_drive, video_path_local)\n",
        "            video_path_local_list.append(video_path_local)\n",
        "    elif video_path.is_file():\n",
        "        video_path_local = Path(\".\").resolve() / (video_path.name)\n",
        "        shutil.copy(video_path, video_path_local)\n",
        "        video_path_local_list.append(video_path_local)\n",
        "        display(Markdown(f\"**{str(video_path)} selected for transcription.**\"))\n",
        "    else:\n",
        "        display(Markdown(f\"**{str(video_path)} does not exist.**\"))\n",
        "\n",
        "else:\n",
        "    raise(TypeError(\"Please select supported input type.\"))\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "    if video_path_local.suffix == \".mp4\":\n",
        "        video_path_local = video_path_local.with_suffix(\".wav\")\n",
        "        result  = subprocess.run([\"ffmpeg\", \"-i\", str(video_path_local.with_suffix(\".mp4\")), \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", str(video_path_local)])\n"
      ],
      "metadata": {
        "id": "xYLPZQX9S7tU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49d4ce9a-14fd-4a14-d87f-efca2f361028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=tWCaFVJMUi8&ab_channel=GateSmashers\n",
            "[youtube] tWCaFVJMUi8: Downloading webpage\n",
            "[youtube] tWCaFVJMUi8: Downloading ios player API JSON\n",
            "[youtube] tWCaFVJMUi8: Downloading android player API JSON\n",
            "[youtube] tWCaFVJMUi8: Downloading m3u8 information\n",
            "[info] tWCaFVJMUi8: Downloading 1 format(s): 140\n",
            "[download] Destination: tWCaFVJMUi8.m4a\n",
            "[download] 100% of   12.44MiB in 00:00:00 at 33.84MiB/s  \n",
            "[FixupM4a] Correcting container of \"tWCaFVJMUi8.m4a\"\n",
            "[ExtractAudio] Destination: tWCaFVJMUi8.wav\n",
            "Deleting original file tWCaFVJMUi8.m4a (pass -k to keep)\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=tWCaFVJMUi8&ab_channel=GateSmashers\n",
            "[youtube] tWCaFVJMUi8: Downloading webpage\n",
            "[youtube] tWCaFVJMUi8: Downloading ios player API JSON\n",
            "[youtube] tWCaFVJMUi8: Downloading android player API JSON\n",
            "[youtube] tWCaFVJMUi8: Downloading m3u8 information\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X0qB9JAzMLY",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30086d75-b514-4257-c8e2-9b55a009ed59"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### tWCaFVJMUi8.wav"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:02.000]  Hello friends, welcome to Gate Smashers\n",
            "[00:02.000 --> 00:05.000]  In this video we are going to discuss about Quick Sort\n",
            "[00:05.000 --> 00:09.000]  And in this video we are going to discuss all the important points related to Quick Sort\n",
            "[00:09.000 --> 00:14.000]  Which are very important for your competitive exams or for your college or university level exams\n",
            "[00:14.000 --> 00:17.000]  And even for your placements\n",
            "[00:17.000 --> 00:22.000]  So guys, quickly like the video and subscribe to the channel if you haven't done it yet\n",
            "[00:22.000 --> 00:26.000]  And please press the bell button so that you don't miss all the latest notifications\n",
            "[00:26.000 --> 00:28.000]  So let's start with Quick Sort\n",
            "[00:28.000 --> 00:33.000]  The first important point is that it is a divide and conquer technology or divide and conquer method\n",
            "[00:33.000 --> 00:35.000]  Now what is divide and conquer?\n",
            "[00:35.000 --> 00:40.000]  Let's say I have a problem and the size of the problem is n\n",
            "[00:40.000 --> 00:42.000]  So what do we do in divide and conquer?\n",
            "[00:42.000 --> 00:45.000]  We divide the big problem into sub problems\n",
            "[00:45.000 --> 00:49.000]  Like if this is a big problem, let's say I am dividing it into n by 2, n by 2 in two parts\n",
            "[00:49.000 --> 00:52.000]  Then n by 4, n by 4, this also has n by 4\n",
            "[00:52.000 --> 00:57.000]  Means we divide the big problem into small parts or into sub problems\n",
            "[00:57.000 --> 00:58.000]  Then we divide the big problem into small parts or into sub problems\n",
            "[00:58.000 --> 01:00.000]  Then we solve all those problems\n",
            "[01:00.000 --> 01:07.000]  And finally we give a final answer by combining their solution\n",
            "[01:07.000 --> 01:11.000]  So the Quick Sort is also partition based\n",
            "[01:11.000 --> 01:14.000]  Or you can say it divides the problem\n",
            "[01:14.000 --> 01:16.000]  But how does it divide?\n",
            "[01:16.000 --> 01:18.000]  How does it partition?\n",
            "[01:18.000 --> 01:20.000]  This is the most important\n",
            "[01:20.000 --> 01:23.000]  And if you have any sorting algorithm\n",
            "[01:23.000 --> 01:27.000]  Talk about any sorting algorithm or searching algorithm\n",
            "[01:27.000 --> 01:29.000]  It is not just about how it works\n",
            "[01:29.000 --> 01:31.000]  Or how its answer will come\n",
            "[01:31.000 --> 01:33.000]  Let's say if I give you an array\n",
            "[01:33.000 --> 01:34.000]  It is an unsorted array\n",
            "[01:34.000 --> 01:36.000]  You have to put a quick sort\n",
            "[01:36.000 --> 01:39.000]  They will not ask you this but it will be the final output\n",
            "[01:39.000 --> 01:40.000]  What will be the final output?\n",
            "[01:40.000 --> 01:42.000]  You sort it and write it\n",
            "[01:42.000 --> 01:43.000]  That is your final answer\n",
            "[01:43.000 --> 01:45.000]  But they will not ask you this, anyone will tell you\n",
            "[01:45.000 --> 01:47.000]  But what can I ask you here?\n",
            "[01:47.000 --> 01:49.000]  First of all, the concept\n",
            "[01:49.000 --> 01:51.000]  How does quick sort work?\n",
            "[01:51.000 --> 01:53.000]  Second, time complexity\n",
            "[01:53.000 --> 01:56.000]  In the best case, in the average case, in the worst case\n",
            "[01:56.000 --> 01:58.000]  How does it work?\n",
            "[01:58.000 --> 01:59.000]  Related to this\n",
            "[01:59.000 --> 02:01.000]  And third, recurrence relation\n",
            "[02:01.000 --> 02:04.000]  Because you know how to write recurrence relation\n",
            "[02:04.000 --> 02:07.000]  Only then you can find out the time complexity\n",
            "[02:07.000 --> 02:11.000]  Because we have already discussed the substitution method or master method\n",
            "[02:11.000 --> 02:13.000]  So let's start here first\n",
            "[02:13.000 --> 02:15.000]  How does it work?\n",
            "[02:15.000 --> 02:18.000]  We have taken a normal unsorted array here\n",
            "[02:18.000 --> 02:20.000]  So see how does it work first?\n",
            "[02:20.000 --> 02:23.000]  What do we give the first element?\n",
            "[02:23.000 --> 02:25.000]  Give the name of the pivot element\n",
            "[02:25.000 --> 02:27.000]  Means what is this?\n",
            "[02:27.000 --> 02:28.000]  It is a pivot element\n",
            "[02:28.000 --> 02:31.000]  Now we have reserved this pivot element here\n",
            "[02:31.000 --> 02:34.000]  And we have taken two pointers here\n",
            "[02:34.000 --> 02:38.000]  One is pointer P and one is pointer Q\n",
            "[02:38.000 --> 02:43.000]  Now the P pointer moves RHS\n",
            "[02:43.000 --> 02:45.000]  And when does it stop?\n",
            "[02:45.000 --> 02:47.000]  Means it will keep incrementing one by one\n",
            "[02:47.000 --> 02:49.000]  But when will it stop?\n",
            "[02:49.000 --> 02:53.000]  When it gets an element greater than pivot\n",
            "[02:53.000 --> 02:54.000]  Keep writing all these points\n",
            "[02:54.000 --> 02:55.000]  When will it stop?\n",
            "[02:55.000 --> 02:57.000]  It will move one by one like this\n",
            "[02:57.000 --> 02:58.000]  Right hand side\n",
            "[02:58.000 --> 02:59.000]  But when will it stop?\n",
            "[02:59.000 --> 03:02.000]  When it gets an element greater than the pivot element\n",
            "[03:02.000 --> 03:04.000]  So it will keep moving like this\n",
            "[03:04.000 --> 03:05.000]  Why like this?\n",
            "[03:05.000 --> 03:07.000]  Q is being decremented\n",
            "[03:07.000 --> 03:10.000]  Means it is moving towards LHS\n",
            "[03:10.000 --> 03:11.000]  And when will it stop?\n",
            "[03:11.000 --> 03:16.000]  When it gets an element lesser than the pivot element\n",
            "[03:16.000 --> 03:18.000]  Now why does it stop?\n",
            "[03:18.000 --> 03:20.000]  Now what does P actually do?\n",
            "[03:20.000 --> 03:23.000]  That all the big elements come on the right side of the pivot element\n",
            "[03:23.000 --> 03:26.000]  And all the small elements come on the left side\n",
            "[03:26.000 --> 03:29.000]  So Q will help to get small elements\n",
            "[03:29.000 --> 03:33.000]  And P will help to get all the big elements on the right side\n",
            "[03:33.000 --> 03:35.000]  You will understand further what are we actually doing\n",
            "[03:35.000 --> 03:38.000]  Now see P will move one by one\n",
            "[03:38.000 --> 03:39.000]  But remember here\n",
            "[03:39.000 --> 03:43.000]  In the last we have to put plus infinite here\n",
            "[03:43.000 --> 03:46.000]  Many times we ask why we put plus infinite\n",
            "[03:46.000 --> 03:47.000]  See it is moving forward\n",
            "[03:47.000 --> 03:49.000]  Let's say if your array is like this\n",
            "[03:49.000 --> 03:50.000]  35\n",
            "[03:50.000 --> 03:51.000]  5\n",
            "[03:51.000 --> 03:52.000]  4\n",
            "[03:52.000 --> 03:53.000]  3\n",
            "[03:53.000 --> 03:54.000]  2\n",
            "[03:54.000 --> 03:55.000]  1\n",
            "[03:55.000 --> 03:56.000]  Like this for example\n",
            "[03:56.000 --> 03:58.000]  Now see 35 is my pivot\n",
            "[03:58.000 --> 03:59.000]  5\n",
            "[03:59.000 --> 04:00.000]  Is 5 greater than?\n",
            "[04:00.000 --> 04:01.000]  No, move to the next\n",
            "[04:01.000 --> 04:02.000]  When will it stop?\n",
            "[04:02.000 --> 04:03.000]  When it gets greater\n",
            "[04:03.000 --> 04:04.000]  Is 4 greater than?\n",
            "[04:04.000 --> 04:05.000]  No, move to the next\n",
            "[04:05.000 --> 04:06.000]  3\n",
            "[04:06.000 --> 04:07.000]  No\n",
            "[04:07.000 --> 04:08.000]  2\n",
            "[04:08.000 --> 04:09.000]  No\n",
            "[04:09.000 --> 04:10.000]  1\n",
            "[04:10.000 --> 04:11.000]  No\n",
            "[04:11.000 --> 04:12.000]  So when will it stop?\n",
            "[04:12.000 --> 04:13.000]  We have to stop it too\n",
            "[04:13.000 --> 04:15.000]  So to stop it we have written plus infinite here\n",
            "[04:15.000 --> 04:19.000]  Because plus infinite will obviously be greater than the pivot element\n",
            "[04:19.000 --> 04:21.000]  Means it will stop here\n",
            "[04:21.000 --> 04:22.000]  It will give garbage value\n",
            "[04:22.000 --> 04:24.000]  So we have written here to stop it\n",
            "[04:24.000 --> 04:25.000]  Now many times the question comes\n",
            "[04:25.000 --> 04:29.000]  Sir if we are increasing Q to the left side\n",
            "[04:29.000 --> 04:30.000]  Then we have to stop Q too\n",
            "[04:30.000 --> 04:33.000]  So should I write minus infinite here?\n",
            "[04:33.000 --> 04:34.000]  No\n",
            "[04:34.000 --> 04:37.000]  When Q will decrement here\n",
            "[04:37.000 --> 04:39.000]  So what is it actually checking?\n",
            "[04:39.000 --> 04:42.000]  It is checking less than equal to\n",
            "[04:42.000 --> 04:44.000]  Means less than equal to the pivot element\n",
            "[04:44.000 --> 04:47.000]  It is checking greater than equal to\n",
            "[04:47.000 --> 04:48.000]  Now see greater than equal to\n",
            "[04:48.000 --> 04:50.000]  Obviously the pivot element is on its left\n",
            "[04:50.000 --> 04:52.000]  And it is increasing further and further\n",
            "[04:52.000 --> 04:53.000]  So the pivot will never come\n",
            "[04:53.000 --> 04:56.000]  But Q is coming towards the pivot\n",
            "[04:56.000 --> 04:58.000]  Now if Q is coming towards the pivot\n",
            "[04:58.000 --> 05:00.000]  So see less than equal to\n",
            "[05:00.000 --> 05:01.000]  Less than equal to\n",
            "[05:01.000 --> 05:02.000]  Less than equal to\n",
            "[05:02.000 --> 05:03.000]  Less than equal to\n",
            "[05:03.000 --> 05:04.000]  Less than equal to\n",
            "[05:04.000 --> 05:05.000]  Less than equal to\n",
            "[05:05.000 --> 05:07.000]  So it will be equal to the pivot\n",
            "[05:07.000 --> 05:09.000]  So it will not move next to this\n",
            "[05:09.000 --> 05:13.000]  So at least it will stop at the pivot automatically\n",
            "[05:13.000 --> 05:14.000]  So this is actually the concept\n",
            "[05:14.000 --> 05:17.000]  How we move P and Q\n",
            "[05:17.000 --> 05:18.000]  Now let's start with the concept\n",
            "[05:18.000 --> 05:19.000]  Let's say P\n",
            "[05:19.000 --> 05:21.000]  We are starting with P first\n",
            "[05:21.000 --> 05:22.000]  P 50\n",
            "[05:22.000 --> 05:24.000]  50 greater than 35\n",
            "[05:24.000 --> 05:25.000]  Yes\n",
            "[05:25.000 --> 05:26.000]  Stop\n",
            "[05:26.000 --> 05:27.000]  Don't move further\n",
            "[05:27.000 --> 05:28.000]  Next come to Q\n",
            "[05:28.000 --> 05:29.000]  Q 45\n",
            "[05:29.000 --> 05:31.000]  45 less than 35\n",
            "[05:31.000 --> 05:32.000]  No\n",
            "[05:32.000 --> 05:33.000]  So move Q further\n",
            "[05:33.000 --> 05:34.000]  90\n",
            "[05:34.000 --> 05:36.000]  90 less than 35\n",
            "[05:36.000 --> 05:37.000]  No\n",
            "[05:37.000 --> 05:38.000]  So move further\n",
            "[05:38.000 --> 05:39.000]  20\n",
            "[05:39.000 --> 05:40.000]  20 less than 35\n",
            "[05:40.000 --> 05:41.000]  Yes\n",
            "[05:41.000 --> 05:42.000]  It has stopped\n",
            "[05:42.000 --> 05:44.000]  Q has stopped here\n",
            "[05:44.000 --> 05:45.000]  P has already stopped here\n",
            "[05:45.000 --> 05:47.000]  Now you have to check\n",
            "[05:47.000 --> 05:48.000]  That P and Q\n",
            "[05:48.000 --> 05:49.000]  Have you ever\n",
            "[05:49.000 --> 05:51.000]  Interchange in each other\n",
            "[05:51.000 --> 05:52.000]  That means P and Q\n",
            "[05:52.000 --> 05:53.000]  Have not crossed each other\n",
            "[05:53.000 --> 05:54.000]  No\n",
            "[05:54.000 --> 05:55.000]  P and Q have not crossed yet\n",
            "[05:55.000 --> 05:57.000]  So what you have to do is\n",
            "[05:57.000 --> 06:00.000]  Swap the elements of both of them\n",
            "[06:00.000 --> 06:01.000]  Swap the elements of both of them\n",
            "[06:01.000 --> 06:03.000]  Swap the elements of both of them\n",
            "[06:03.000 --> 06:04.000]  That means your output\n",
            "[06:04.000 --> 06:05.000]  Will come like this\n",
            "[06:05.000 --> 06:08.000]  Now 20 has come here\n",
            "[06:08.000 --> 06:09.000]  15 as it is\n",
            "[06:09.000 --> 06:10.000]  25 as it is\n",
            "[06:10.000 --> 06:11.000]  80 as it is\n",
            "[06:11.000 --> 06:13.000]  What has come in place of 20\n",
            "[06:13.000 --> 06:14.000]  50\n",
            "[06:14.000 --> 06:15.000]  90\n",
            "[06:15.000 --> 06:16.000]  45\n",
            "[06:16.000 --> 06:17.000]  Plus infinite\n",
            "[06:17.000 --> 06:18.000]  In this way\n",
            "[06:18.000 --> 06:19.000]  Now it will come\n",
            "[06:19.000 --> 06:20.000]  So now see\n",
            "[06:20.000 --> 06:21.000]  P was here\n",
            "[06:21.000 --> 06:24.000]  Q was in this position\n",
            "[06:24.000 --> 06:25.000]  Now move further\n",
            "[06:25.000 --> 06:26.000]  Next P\n",
            "[06:26.000 --> 06:27.000]  P greater than\n",
            "[06:27.000 --> 06:29.000]  Means 15 greater than 35\n",
            "[06:29.000 --> 06:30.000]  No\n",
            "[06:30.000 --> 06:31.000]  25\n",
            "[06:31.000 --> 06:33.000]  25 greater than 35\n",
            "[06:33.000 --> 06:34.000]  No\n",
            "[06:34.000 --> 06:35.000]  80\n",
            "[06:35.000 --> 06:37.000]  80 greater than 35\n",
            "[06:37.000 --> 06:38.000]  Yes\n",
            "[06:38.000 --> 06:39.000]  Stop P\n",
            "[06:39.000 --> 06:40.000]  P has been stopped here\n",
            "[06:40.000 --> 06:42.000]  But Q also has to be run simultaneously\n",
            "[06:42.000 --> 06:43.000]  But I am running one by one\n",
            "[06:43.000 --> 06:45.000]  You have to run Q equally\n",
            "[06:45.000 --> 06:46.000]  Q 50\n",
            "[06:46.000 --> 06:47.000]  Less than 35\n",
            "[06:47.000 --> 06:48.000]  No\n",
            "[06:48.000 --> 06:49.000]  Next 80\n",
            "[06:49.000 --> 06:50.000]  80 less than 35\n",
            "[06:50.000 --> 06:51.000]  No\n",
            "[06:51.000 --> 06:52.000]  Next 25\n",
            "[06:52.000 --> 06:54.000]  25 less than 35\n",
            "[06:54.000 --> 06:55.000]  Yes\n",
            "[06:55.000 --> 06:56.000]  So Q stopped here\n",
            "[06:56.000 --> 06:57.000]  P stopped here\n",
            "[06:57.000 --> 06:59.000]  Now you have to check\n",
            "[06:59.000 --> 07:02.000]  Did P and Q cross each other\n",
            "[07:02.000 --> 07:03.000]  Here was P\n",
            "[07:03.000 --> 07:04.000]  Here was Q\n",
            "[07:04.000 --> 07:05.000]  It was not done in this\n",
            "[07:05.000 --> 07:06.000]  But now see\n",
            "[07:06.000 --> 07:08.000]  P and Q have crossed each other\n",
            "[07:08.000 --> 07:09.000]  Q came here\n",
            "[07:09.000 --> 07:10.000]  P came there\n",
            "[07:10.000 --> 07:12.000]  Whenever this type of situation comes\n",
            "[07:12.000 --> 07:15.000]  That either P and Q are in the same position\n",
            "[07:15.000 --> 07:17.000]  Or Q crosses\n",
            "[07:17.000 --> 07:19.000]  Now in this case what you have to do\n",
            "[07:19.000 --> 07:23.000]  You have to simply replace the pivot element\n",
            "[07:23.000 --> 07:24.000]  With whom\n",
            "[07:24.000 --> 07:26.000]  With Q element\n",
            "[07:26.000 --> 07:27.000]  Remember\n",
            "[07:27.000 --> 07:29.000]  Q whoever is being pointed out\n",
            "[07:29.000 --> 07:30.000]  With that element\n",
            "[07:30.000 --> 07:32.000]  Swap the pivot\n",
            "[07:32.000 --> 07:33.000]  Means\n",
            "[07:33.000 --> 07:35.000]  25 came here\n",
            "[07:35.000 --> 07:36.000]  20 here\n",
            "[07:36.000 --> 07:37.000]  15 here\n",
            "[07:37.000 --> 07:39.000]  35 here\n",
            "[07:39.000 --> 07:40.000]  Where is Q pointed out\n",
            "[07:40.000 --> 07:41.000]  25\n",
            "[07:41.000 --> 07:42.000]  Swap 25 here\n",
            "[07:42.000 --> 07:44.000]  Swap with the pivot element\n",
            "[07:44.000 --> 07:46.000]  Don't swap with P\n",
            "[07:46.000 --> 07:49.000]  Swap with P when they have not crossed\n",
            "[07:49.000 --> 07:50.000]  Or did not come equally\n",
            "[07:50.000 --> 07:52.000]  But if they came equally or crossed\n",
            "[07:52.000 --> 07:54.000]  Then now you have to do with the pivot\n",
            "[07:54.000 --> 07:56.000]  Rest of the elements are same\n",
            "[07:56.000 --> 07:57.000]  80\n",
            "[07:57.000 --> 07:58.000]  50\n",
            "[07:58.000 --> 07:59.000]  90\n",
            "[07:59.000 --> 08:00.000]  40\n",
            "[08:00.000 --> 08:01.000]  5\n",
            "[08:01.000 --> 08:02.000]  Clear point\n",
            "[08:02.000 --> 08:03.000]  So this is actually the concept here\n",
            "[08:03.000 --> 08:04.000]  Now see\n",
            "[08:04.000 --> 08:05.000]  35 is yours\n",
            "[08:05.000 --> 08:07.000]  This is called one pass\n",
            "[08:07.000 --> 08:09.000]  Means it was the first pass\n",
            "[08:09.000 --> 08:10.000]  It was the first step\n",
            "[08:10.000 --> 08:11.000]  Now see\n",
            "[08:11.000 --> 08:12.000]  As soon as the first step is completed\n",
            "[08:12.000 --> 08:14.000]  Your pivot element\n",
            "[08:14.000 --> 08:15.000]  It is in the right position\n",
            "[08:15.000 --> 08:16.000]  It reached the right position\n",
            "[08:16.000 --> 08:18.000]  See 35 is in the right position\n",
            "[08:18.000 --> 08:20.000]  All the smaller than 35\n",
            "[08:20.000 --> 08:21.000]  Here\n",
            "[08:21.000 --> 08:22.000]  All the bigger than 35\n",
            "[08:22.000 --> 08:23.000]  Here\n",
            "[08:23.000 --> 08:24.000]  It is not even a sort\n",
            "[08:24.000 --> 08:25.000]  Now only one step is done\n",
            "[08:25.000 --> 08:27.000]  But after this step\n",
            "[08:27.000 --> 08:29.000]  35 reached its right position\n",
            "[08:29.000 --> 08:31.000]  And the smaller than this is here\n",
            "[08:31.000 --> 08:33.000]  The bigger than this is here\n",
            "[08:33.000 --> 08:36.000]  Means you have divided this problem into two parts\n",
            "[08:36.000 --> 08:37.000]  25\n",
            "[08:37.000 --> 08:38.000]  20\n",
            "[08:38.000 --> 08:40.000]  15 came here\n",
            "[08:40.000 --> 08:41.000]  80\n",
            "[08:41.000 --> 08:42.000]  50\n",
            "[08:42.000 --> 08:43.000]  90\n",
            "[08:43.000 --> 08:44.000]  45\n",
            "[08:44.000 --> 08:45.000]  Came here\n",
            "[08:45.000 --> 08:48.000]  And your 35 pivot is in the right position\n",
            "[08:48.000 --> 08:51.000]  Now your problem will be divided into two parts\n",
            "[08:51.000 --> 08:53.000]  Now put the quick sort here also\n",
            "[08:53.000 --> 08:54.000]  Put the quick sort here also\n",
            "[08:54.000 --> 08:56.000]  Now if I put the quick sort here\n",
            "[08:56.000 --> 08:57.000]  Then what will happen\n",
            "[08:57.000 --> 08:59.000]  25 is the pivot element\n",
            "[08:59.000 --> 09:01.000]  So 25 is my pivot element\n",
            "[09:01.000 --> 09:03.000]  P is yours\n",
            "[09:03.000 --> 09:05.000]  Q is yours\n",
            "[09:05.000 --> 09:06.000]  Simple\n",
            "[09:06.000 --> 09:07.000]  As we did earlier\n",
            "[09:07.000 --> 09:08.000]  Now see\n",
            "[09:08.000 --> 09:10.000]  P greater than 25\n",
            "[09:10.000 --> 09:11.000]  No\n",
            "[09:11.000 --> 09:12.000]  Move ahead\n",
            "[09:12.000 --> 09:14.000]  15 greater than 25\n",
            "[09:14.000 --> 09:15.000]  No\n",
            "[09:15.000 --> 09:16.000]  Move ahead\n",
            "[09:16.000 --> 09:17.000]  What is ahead\n",
            "[09:17.000 --> 09:18.000]  Plus infinite\n",
            "[09:18.000 --> 09:19.000]  So what stopped at plus infinite\n",
            "[09:19.000 --> 09:20.000]  P stopped\n",
            "[09:20.000 --> 09:21.000]  It went out from here\n",
            "[09:21.000 --> 09:22.000]  P and stopped here\n",
            "[09:22.000 --> 09:23.000]  We have to check Q also\n",
            "[09:23.000 --> 09:26.000]  15 less than 25\n",
            "[09:26.000 --> 09:27.000]  Yes\n",
            "[09:27.000 --> 09:28.000]  It will stop here\n",
            "[09:28.000 --> 09:30.000]  Because Q element is less\n",
            "[09:30.000 --> 09:31.000]  So it will be stopped\n",
            "[09:31.000 --> 09:32.000]  Now you check\n",
            "[09:32.000 --> 09:34.000]  Have P and Q crossed each other\n",
            "[09:34.000 --> 09:36.000]  Crossed\n",
            "[09:36.000 --> 09:37.000]  When these two have crossed each other\n",
            "[09:37.000 --> 09:39.000]  What did I tell\n",
            "[09:39.000 --> 09:42.000]  Exchange the pivot element with the Q one\n",
            "[09:42.000 --> 09:43.000]  So see\n",
            "[09:43.000 --> 09:44.000]  15 came ahead\n",
            "[09:44.000 --> 09:46.000]  20 as it is\n",
            "[09:46.000 --> 09:47.000]  25 is here\n",
            "[09:47.000 --> 09:48.000]  And the pivot here\n",
            "[09:48.000 --> 09:50.000]  You don't have to do anything as it is\n",
            "[09:50.000 --> 09:51.000]  35 is as it is\n",
            "[09:51.000 --> 09:52.000]  So see\n",
            "[09:52.000 --> 09:54.000]  This sub-area is sorted\n",
            "[09:54.000 --> 09:56.000]  Now we have to do the same here\n",
            "[09:56.000 --> 09:59.000]  80 was your pivot\n",
            "[09:59.000 --> 10:00.000]  P was yours\n",
            "[10:00.000 --> 10:02.000]  Q was yours\n",
            "[10:02.000 --> 10:03.000]  And plus infinity\n",
            "[10:03.000 --> 10:05.000]  This is actually divided into two parts\n",
            "[10:05.000 --> 10:06.000]  So this is running separately\n",
            "[10:06.000 --> 10:07.000]  This is running separately\n",
            "[10:07.000 --> 10:08.000]  So same here\n",
            "[10:08.000 --> 10:09.000]  P\n",
            "[10:09.000 --> 10:11.000]  50 greater than 80\n",
            "[10:11.000 --> 10:12.000]  No\n",
            "[10:12.000 --> 10:13.000]  Move ahead\n",
            "[10:13.000 --> 10:15.000]  90 greater than 80\n",
            "[10:15.000 --> 10:16.000]  Yes\n",
            "[10:16.000 --> 10:17.000]  So P will now point to who\n",
            "[10:17.000 --> 10:18.000]  90\n",
            "[10:18.000 --> 10:19.000]  Same as this\n",
            "[10:19.000 --> 10:21.000]  45 less than 80\n",
            "[10:21.000 --> 10:22.000]  Yes\n",
            "[10:22.000 --> 10:24.000]  Q will be stopped here\n",
            "[10:24.000 --> 10:26.000]  So have P and Q crossed each other\n",
            "[10:26.000 --> 10:27.000]  No\n",
            "[10:27.000 --> 10:28.000]  So in this case\n",
            "[10:28.000 --> 10:30.000]  We have to swap these two\n",
            "[10:30.000 --> 10:32.000]  Have nothing to do with the pivot\n",
            "[10:32.000 --> 10:34.000]  Means the swap of these two\n",
            "[10:34.000 --> 10:35.000]  So I write here\n",
            "[10:35.000 --> 10:36.000]  80\n",
            "[10:36.000 --> 10:37.000]  50\n",
            "[10:37.000 --> 10:38.000]  45\n",
            "[10:38.000 --> 10:39.000]  90\n",
            "[10:39.000 --> 10:40.000]  That's it\n",
            "[10:40.000 --> 10:41.000]  Now P was here\n",
            "[10:41.000 --> 10:42.000]  Q was here\n",
            "[10:42.000 --> 10:44.000]  And plus infinity as it is\n",
            "[10:44.000 --> 10:45.000]  Now see you\n",
            "[10:45.000 --> 10:46.000]  Next\n",
            "[10:46.000 --> 10:47.000]  90\n",
            "[10:47.000 --> 10:48.000]  90 greater than 80\n",
            "[10:48.000 --> 10:49.000]  Yes\n",
            "[10:49.000 --> 10:50.000]  So your P\n",
            "[10:50.000 --> 10:52.000]  Stopped at this point\n",
            "[10:52.000 --> 10:53.000]  Check Q\n",
            "[10:53.000 --> 10:54.000]  Q 90 less than\n",
            "[10:54.000 --> 10:55.000]  No\n",
            "[10:55.000 --> 10:56.000]  Next will be Q\n",
            "[10:56.000 --> 10:58.000]  45 less than 80\n",
            "[10:58.000 --> 10:59.000]  45 less than 80\n",
            "[10:59.000 --> 11:00.000]  Yes\n",
            "[11:00.000 --> 11:01.000]  So Q stopped here\n",
            "[11:01.000 --> 11:02.000]  Q is checking less\n",
            "[11:02.000 --> 11:03.000]  That is greater\n",
            "[11:03.000 --> 11:04.000]  So see\n",
            "[11:04.000 --> 11:06.000]  Both positions have crossed each other\n",
            "[11:06.000 --> 11:09.000]  P and Q have crossed each other\n",
            "[11:09.000 --> 11:10.000]  If they have crossed each other\n",
            "[11:10.000 --> 11:11.000]  So what you have to do?\n",
            "[11:11.000 --> 11:12.000]  So what you have to do?\n",
            "[11:12.000 --> 11:15.000]  Write the pivot element instead of Q\n",
            "[11:15.000 --> 11:16.000]  Means\n",
            "[11:16.000 --> 11:19.000]  Q is 45 instead of the pivot\n",
            "[11:19.000 --> 11:20.000]  50 as it is\n",
            "[11:20.000 --> 11:22.000]  And pivot in the position of Q\n",
            "[11:22.000 --> 11:23.000]  Which was the pivot?\n",
            "[11:23.000 --> 11:24.000]  80\n",
            "[11:24.000 --> 11:25.000]  80 came here\n",
            "[11:25.000 --> 11:26.000]  90 as it is\n",
            "[11:26.000 --> 11:27.000]  So see\n",
            "[11:27.000 --> 11:29.000]  Overall your array\n",
            "[11:29.000 --> 11:31.000]  What has happened?\n",
            "[11:31.000 --> 11:32.000]  It has been sorted\n",
            "[11:32.000 --> 11:33.000]  So in this way\n",
            "[11:33.000 --> 11:34.000]  Actually\n",
            "[11:34.000 --> 11:36.000]  Quick sort works\n",
            "[11:36.000 --> 11:37.000]  This is a normal case\n",
            "[11:37.000 --> 11:38.000]  Means\n",
            "[11:38.000 --> 11:39.000]  Say average case or best case\n",
            "[11:39.000 --> 11:40.000]  We have now\n",
            "[11:40.000 --> 11:42.000]  No problem of worst case here\n",
            "[11:42.000 --> 11:44.000]  So in normal case\n",
            "[11:44.000 --> 11:45.000]  If your problem is\n",
            "[11:45.000 --> 11:47.000]  Its size is N\n",
            "[11:47.000 --> 11:49.000]  So if your pivot element\n",
            "[11:49.000 --> 11:52.000]  Actually the whole story depends on the pivot element\n",
            "[11:52.000 --> 11:55.000]  That where will the pivot element go and sit\n",
            "[11:55.000 --> 11:56.000]  After the first pass\n",
            "[11:56.000 --> 11:58.000]  If your pivot element\n",
            "[11:58.000 --> 11:59.000]  In the middle\n",
            "[11:59.000 --> 12:00.000]  Means\n",
            "[12:00.000 --> 12:01.000]  Let's say this is my N size\n",
            "[12:01.000 --> 12:03.000]  And if this was your pivot\n",
            "[12:03.000 --> 12:04.000]  After the first pass\n",
            "[12:04.000 --> 12:06.000]  If the pivot reaches the middle\n",
            "[12:06.000 --> 12:08.000]  So see your problem will be divided\n",
            "[12:08.000 --> 12:09.000]  N by 2\n",
            "[12:09.000 --> 12:10.000]  N by 2\n",
            "[12:10.000 --> 12:11.000]  Minus 1\n",
            "[12:11.000 --> 12:12.000]  Why did you do minus 1?\n",
            "[12:12.000 --> 12:13.000]  Because the pivot element was this\n",
            "[12:13.000 --> 12:14.000]  Means\n",
            "[12:14.000 --> 12:15.000]  On an average\n",
            "[12:15.000 --> 12:16.000]  You can say\n",
            "[12:16.000 --> 12:17.000]  It will be divided into two parts\n",
            "[12:17.000 --> 12:18.000]  Now N by 4\n",
            "[12:18.000 --> 12:19.000]  N by 4\n",
            "[12:19.000 --> 12:20.000]  N by 4\n",
            "[12:20.000 --> 12:21.000]  N by 4\n",
            "[12:21.000 --> 12:22.000]  It is being divided in this way\n",
            "[12:22.000 --> 12:23.000]  So what you can say\n",
            "[12:23.000 --> 12:24.000]  That my problem\n",
            "[12:24.000 --> 12:26.000]  If my problem is T of N\n",
            "[12:26.000 --> 12:27.000]  So it is being divided\n",
            "[12:27.000 --> 12:28.000]  N by 2\n",
            "[12:28.000 --> 12:29.000]  Plus\n",
            "[12:29.000 --> 12:30.000]  N by 2\n",
            "[12:30.000 --> 12:31.000]  It is being divided into two parts\n",
            "[12:31.000 --> 12:32.000]  Plus\n",
            "[12:32.000 --> 12:33.000]  N time\n",
            "[12:33.000 --> 12:34.000]  Which is being applied here\n",
            "[12:34.000 --> 12:35.000]  What is N time?\n",
            "[12:35.000 --> 12:37.000]  In every step\n",
            "[12:37.000 --> 12:38.000]  When you did the first pass\n",
            "[12:38.000 --> 12:40.000]  When you completed this step\n",
            "[12:40.000 --> 12:43.000]  So you had to scan the whole array\n",
            "[12:43.000 --> 12:46.000]  Then your one pass is completed\n",
            "[12:46.000 --> 12:47.000]  You have scanned the whole array\n",
            "[12:47.000 --> 12:49.000]  Then your one pass is completed\n",
            "[12:49.000 --> 12:53.000]  So this N time is for the scanning entire array\n",
            "[12:53.000 --> 12:54.000]  Because how much is the size of the array?\n",
            "[12:54.000 --> 12:55.000]  Maximum\n",
            "[12:55.000 --> 12:56.000]  N\n",
            "[12:56.000 --> 12:59.000]  So what is your actual recurrence relation?\n",
            "[12:59.000 --> 13:02.000]  2TN by 2 plus N\n",
            "[13:02.000 --> 13:04.000]  This is the final recurrence relation\n",
            "[13:04.000 --> 13:05.000]  In the average case\n",
            "[13:05.000 --> 13:07.000]  We are talking about the normal case\n",
            "[13:07.000 --> 13:08.000]  So if you solve it\n",
            "[13:08.000 --> 13:09.000]  We have already done\n",
            "[13:09.000 --> 13:10.000]  Master method also\n",
            "[13:10.000 --> 13:11.000]  And even substitution method also\n",
            "[13:11.000 --> 13:12.000]  If you solve it\n",
            "[13:12.000 --> 13:13.000]  Then the answer will be\n",
            "[13:13.000 --> 13:14.000]  N log N\n",
            "[13:14.000 --> 13:19.000]  So that's why the average case time complexity of quick sort is\n",
            "[13:19.000 --> 13:20.000]  N log N\n",
            "[13:20.000 --> 13:22.000]  So in the next video we will talk about\n",
            "[13:22.000 --> 13:24.000]  Worst case time complexity\n",
            "[13:24.000 --> 13:25.000]  Thank you\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Transcript file created: /content/drive/My Drive/Colab Notebooks/Whisper Youtube/tWCaFVJMUi8.txt**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Transcript file created: /content/drive/My Drive/Colab Notebooks/Whisper Youtube/tWCaFVJMUi8.vtt**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Transcript file created: /content/drive/My Drive/Colab Notebooks/Whisper Youtube/tWCaFVJMUi8.srt**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Transcript file created: /content/drive/My Drive/Colab Notebooks/Whisper Youtube/tWCaFVJMUi8.tsv**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Transcript file created: /content/drive/My Drive/Colab Notebooks/Whisper Youtube/tWCaFVJMUi8.json**"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # **Run the model** üöÄ\n",
        "\n",
        "#@markdown Run this cell to execute the transcription of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "\n",
        "#@markdown ## **Parameters** ‚öôÔ∏è\n",
        "\n",
        "#@markdown ### **Behavior control**\n",
        "#@markdown ---\n",
        "language = \"English\" #@param ['Auto detection', 'Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Assamese', 'Azerbaijani', 'Bashkir', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Breton', 'Bulgarian', 'Burmese', 'Castilian', 'Catalan', 'Chinese', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Estonian', 'Faroese', 'Finnish', 'Flemish', 'French', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hungarian', 'Icelandic', 'Indonesian', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Lao', 'Latin', 'Latvian', 'Letzeburgesch', 'Lingala', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Moldavian', 'Moldovan', 'Mongolian', 'Myanmar', 'Nepali', 'Norwegian', 'Nynorsk', 'Occitan', 'Panjabi', 'Pashto', 'Persian', 'Polish', 'Portuguese', 'Punjabi', 'Pushto', 'Romanian', 'Russian', 'Sanskrit', 'Serbian', 'Shona', 'Sindhi', 'Sinhala', 'Sinhalese', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog', 'Tajik', 'Tamil', 'Tatar', 'Telugu', 'Thai', 'Tibetan', 'Turkish', 'Turkmen', 'Ukrainian', 'Urdu', 'Uzbek', 'Valencian', 'Vietnamese', 'Welsh', 'Yiddish', 'Yoruba']\n",
        "#@markdown > Language spoken in the audio, use `Auto detection` to let Whisper detect the language.\n",
        "#@markdown ---\n",
        "verbose = 'Live transcription' #@param ['Live transcription', 'Progress bar', 'None']\n",
        "#@markdown > Whether to print out the progress and debug messages.\n",
        "#@markdown ---\n",
        "output_format = 'all' #@param ['txt', 'vtt', 'srt', 'tsv', 'json', 'all']\n",
        "#@markdown > Type of file to generate to record the transcription.\n",
        "#@markdown ---\n",
        "task = 'translate' #@param ['transcribe', 'translate']\n",
        "#@markdown > Whether to perform X->X speech recognition (`transcribe`) or X->English translation (`translate`).\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown <br/>\n",
        "\n",
        "#@markdown ### **Optional: Fine tunning**\n",
        "#@markdown ---\n",
        "temperature = 0.15 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "#@markdown > Temperature to use for sampling.\n",
        "#@markdown ---\n",
        "temperature_increment_on_fallback = 0.2 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "#@markdown > Temperature to increase when falling back when the decoding fails to meet either of the thresholds below.\n",
        "#@markdown ---\n",
        "best_of = 5 #@param {type:\"integer\"}\n",
        "#@markdown > Number of candidates when sampling with non-zero temperature.\n",
        "#@markdown ---\n",
        "beam_size = 8 #@param {type:\"integer\"}\n",
        "#@markdown > Number of beams in beam search, only applicable when temperature is zero.\n",
        "#@markdown ---\n",
        "patience = 1.0 #@param {type:\"number\"}\n",
        "#@markdown > Optional patience value to use in beam decoding, as in [*Beam Decoding with Controlled Patience*](https://arxiv.org/abs/2204.05424), the default (1.0) is equivalent to conventional beam search.\n",
        "#@markdown ---\n",
        "length_penalty = -0.05 #@param {type:\"slider\", min:-0.05, max:1, step:0.05}\n",
        "#@markdown > Optional token length penalty coefficient (alpha) as in [*Google's Neural Machine Translation System*](https://arxiv.org/abs/1609.08144), set to negative value to uses simple length normalization.\n",
        "#@markdown ---\n",
        "suppress_tokens = \"-1\" #@param {type:\"string\"}\n",
        "#@markdown > Comma-separated list of token ids to suppress during sampling; '-1' will suppress most special characters except common punctuations.\n",
        "#@markdown ---\n",
        "initial_prompt = \"\" #@param {type:\"string\"}\n",
        "#@markdown > Optional text to provide as a prompt for the first window.\n",
        "#@markdown ---\n",
        "condition_on_previous_text = True #@param {type:\"boolean\"}\n",
        "#@markdown > if True, provide the previous output of the model as a prompt for the next window; disabling may make the text inconsistent across windows, but the model becomes less prone to getting stuck in a failure loop.\n",
        "#@markdown ---\n",
        "fp16 = True #@param {type:\"boolean\"}\n",
        "#@markdown > whether to perform inference in fp16.\n",
        "#@markdown ---\n",
        "compression_ratio_threshold = 2.4 #@param {type:\"number\"}\n",
        "#@markdown > If the gzip compression ratio is higher than this value, treat the decoding as failed.\n",
        "#@markdown ---\n",
        "logprob_threshold = -1.0 #@param {type:\"number\"}\n",
        "#@markdown > If the average log probability is lower than this value, treat the decoding as failed.\n",
        "#@markdown ---\n",
        "no_speech_threshold = 0.6 #@param {type:\"slider\", min:-0.0, max:1, step:0.05}\n",
        "#@markdown > If the probability of the <|nospeech|> token is higher than this value AND the decoding has failed due to `logprob_threshold`, consider the segment as silence.\n",
        "#@markdown ---\n",
        "\n",
        "verbose_lut = {\n",
        "    'Live transcription': True,\n",
        "    'Progress bar': False,\n",
        "    'None': None\n",
        "}\n",
        "\n",
        "args = dict(\n",
        "    language = (None if language == \"Auto detection\" else language),\n",
        "    verbose = verbose_lut[verbose],\n",
        "    task = task,\n",
        "    temperature = temperature,\n",
        "    temperature_increment_on_fallback = temperature_increment_on_fallback,\n",
        "    best_of = best_of,\n",
        "    beam_size = beam_size,\n",
        "    patience=patience,\n",
        "    length_penalty=(length_penalty if length_penalty>=0.0 else None),\n",
        "    suppress_tokens=suppress_tokens,\n",
        "    initial_prompt=(None if not initial_prompt else initial_prompt),\n",
        "    condition_on_previous_text=condition_on_previous_text,\n",
        "    fp16=fp16,\n",
        "    compression_ratio_threshold=compression_ratio_threshold,\n",
        "    logprob_threshold=logprob_threshold,\n",
        "    no_speech_threshold=no_speech_threshold\n",
        ")\n",
        "\n",
        "temperature = args.pop(\"temperature\")\n",
        "temperature_increment_on_fallback = args.pop(\"temperature_increment_on_fallback\")\n",
        "if temperature_increment_on_fallback is not None:\n",
        "    temperature = tuple(np.arange(temperature, 1.0 + 1e-6, temperature_increment_on_fallback))\n",
        "else:\n",
        "    temperature = [temperature]\n",
        "\n",
        "if Model.endswith(\".en\") and args[\"language\"] not in {\"en\", \"English\"}:\n",
        "    warnings.warn(f\"{Model} is an English-only model but receipted '{args['language']}'; using English instead.\")\n",
        "    args[\"language\"] = \"en\"\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "    display(Markdown(f\"### {video_path_local}\"))\n",
        "\n",
        "    video_transcription = whisper.transcribe(\n",
        "        whisper_model,\n",
        "        str(video_path_local),\n",
        "        temperature=temperature,\n",
        "        **args,\n",
        "    )\n",
        "\n",
        "    # Save output\n",
        "    whisper.utils.get_writer(\n",
        "        output_format=output_format,\n",
        "        output_dir=video_path_local.parent\n",
        "    )(\n",
        "        video_transcription,\n",
        "        str(video_path_local.stem),\n",
        "        options=dict(\n",
        "            highlight_words=False,\n",
        "            max_line_count=None,\n",
        "            max_line_width=None,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    def exportTranscriptFile(ext: str):\n",
        "        local_path = video_path_local.parent / video_path_local.with_suffix(ext)\n",
        "        export_path = drive_whisper_path / video_path_local.with_suffix(ext)\n",
        "        shutil.copy(\n",
        "            local_path,\n",
        "            export_path\n",
        "        )\n",
        "        display(Markdown(f\"**Transcript file created: {export_path}**\"))\n",
        "\n",
        "    if output_format==\"all\":\n",
        "        for ext in ('.txt', '.vtt', '.srt', '.tsv', '.json'):\n",
        "            exportTranscriptFile(ext)\n",
        "    else:\n",
        "        exportTranscriptFile(\".\" + output_format)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ad6n1m4deAHp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}